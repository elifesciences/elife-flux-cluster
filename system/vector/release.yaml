---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: vector
spec:
  interval: 1m
  releaseName: vector
  chart:
    spec:
      chart: vector
      version: 0.33.0
      sourceRef:
        kind: HelmRepository
        name: vector
      interval: 1m
  install:
    remediation:
      retries: 5

  values:
    role: Agent
    podMonitor:
      enabled: true
    resources:
      requests:
        cpu: 10m
        memory: 50Mi
    extraVolumes:
    - name: gcp-data-hub-project-log-shipping
      secret:
        secretName: gcp-data-hub-project-log-shipping
    extraVolumeMounts:
    - name: gcp-data-hub-project-log-shipping
      mountPath: /etc/gcp-data-hub-project-log-shipping
      readOnly: true
    env:
      - name: VECTOR_LOG
        value: info
    tolerations:
    - effect: NoSchedule
      operator: Exists
    customConfig:
      data_dir: /vector-data-dir
      api:
        enabled: true
        address: 127.0.0.1:8686
        playground: false
      sources:
        logs:
          type: kubernetes_logs
        host_metrics:
          filesystem:
            devices:
              excludes: [binfmt_misc]
            filesystems:
              excludes: [binfmt_misc]
            mountPoints:
              excludes: ["*/proc/sys/fs/binfmt_misc"]
          type: host_metrics
        internal_metrics:
          type: internal_metrics
        nginx_logs:
          type: kubernetes_logs
          extra_label_selector: app.kubernetes.io/name==ingress-nginx
      transforms:
        json_logs:
          type: remap
          inputs:
            - logs
          source: |
            json, err = parse_json(.message)
            if err == null {
              .json = json
              del(.message)
            }
        nginx_json_parse:
          type: remap
          inputs:
            - nginx_logs
          source: |
            json, err = parse_json(.message)
            if err != null {
              abort
            }
            . = json
        # filter all nginx logs for just the sciety labs request URLs
        filter_nginx_sciety_labs:
          type: filter
          inputs:
            - nginx_json_parse
          condition: |
            starts_with(string(.httpRequest.requestUrl) ?? "", "sciety-labs.elifesciences.org") ||
            starts_with(string(.httpRequest.requestUrl) ?? "", "sciety-discovery.elifesciences.org")
      sinks:
        prom_exporter:
          type: prometheus_exporter
          inputs: [host_metrics, internal_metrics]
          address: 0.0.0.0:9090
        # Ship just sciety labs filtered nginx logs to GCP
        bigquery_gcp:
          type: gcp_cloud_storage
          inputs:
            - filter_nginx_sciety_labs
          bucket: elife-cluster-logs
          credentials_path: /etc/gcp-data-hub-project-log-shipping/credentials.json
          key_prefix: ${cluster_name}/sciety-labs/dt=%F/
          filename_extension: jsonl
          encoding:
            codec: native_json
        loki:
          type: loki
          inputs:
          - json_logs
          endpoint: http://loki-gateway.loki/
          encoding:
            codec: json
          labels:
            host: "${HOSTNAME_NONSENSE:-'$HOSTNAME'}"
            file: "{{`{{ file }}`}}"
            stream: "{{`{{ stream }}`}}"
            source_type: "{{`{{ source_type }}`}}"
            namespace: "{{`{{ kubernetes.pod_namespace }}`}}"
            pod: "{{`{{ kubernetes.pod_name }}`}}"
            uid: "{{`{{ kubernetes.pod_uid }}`}}"
            'labels_*': "{{`{{ kubernetes.pod_labels }}`}}"
