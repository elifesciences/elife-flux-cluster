---
apiVersion: opensearch.opster.io/v1
kind: OpenSearchCluster
metadata:
  name: opensearch-staging
  namespace: data-hub
spec:
  confMgmt:
    smartScaler: true
  general:
    serviceName: opensearch-staging
    serviceAccount: opensearch-staging
    version: 2.9.0
    monitoring:
      enable: false
    pluginsList:
    - "https://github.com/aiven/prometheus-exporter-plugin-for-opensearch/releases/download/2.9.0.0/prometheus-exporter-2.9.0.0.zip"
    - "repository-s3"
    snapshotRepositories:
    - name: ${aws_backup_s3_bucket}
      type: s3
      settings:
        bucket: ${aws_backup_s3_bucket}
        region: ${aws_region}
        base_path: data-hub/opensearch/staging
    # This is to work around JRE permission issues, see https://github.com/opensearch-project/opensearch-k8s-operator/issues/442
    additionalVolumes:
    - name: aws-iam-token
      path: /usr/share/opensearch/config/aws-iam-token
  dashboards:
    version: 2.9.0
    enable: true
    replicas: 1
  nodePools:
  - component: cluster-managers
    replicas: 3
    additionalConfig:
      # This is to work around JRE permission issues, see https://github.com/opensearch-project/opensearch-k8s-operator/issues/442
      s3.client.default.identity_token_file: /usr/share/opensearch/config/aws-iam-token/token
    resources:
      requests:
        memory: "2120Mi"
        cpu: "200m"
      limits:
        memory: "2120Mi"
    roles:
    - "cluster_manager"
    diskSize: 10Gi
    topologySpreadConstraints:
    - maxSkew: 1
      topologyKey: kubernetes.io/hostname
      whenUnsatisfiable: DoNotSchedule
      labelSelector:
        matchLabels:
          opster.io/opensearch-cluster: opensearch-staging
          opster.io/opensearch-nodepool: cluster-managers
    pdb:
      enable: true
      maxUnavailable: 1
    persistence:
      pvc:
        storageClass: data-hub-gp3
        accessModes:
          - ReadWriteOnce
  - component: data-nodes
    replicas: 3
    additionalConfig:
      # This is to work around JRE permission issues, see https://github.com/opensearch-project/opensearch-k8s-operator/issues/442
      s3.client.default.identity_token_file: /usr/share/opensearch/config/aws-iam-token/token
    resources:
      requests:
        memory: "2349Mi"
        cpu: "1000m"
      limits:
        memory: "2349Mi"
    roles:
    - "data"
    diskSize: 200Gi
    topologySpreadConstraints:
    - maxSkew: 1
      topologyKey: kubernetes.io/hostname
      whenUnsatisfiable: DoNotSchedule
      labelSelector:
        matchLabels:
          opster.io/opensearch-cluster: opensearch-staging
          opster.io/opensearch-nodepool: data-nodes
    pdb:
      enable: true
      maxUnavailable: 1
    persistence:
      pvc:
        storageClass: data-hub-gp3
        accessModes:
          - ReadWriteOnce
  - component: ingest
    replicas: 1
    additionalConfig:
      # This is to work around JRE permission issues, see https://github.com/opensearch-project/opensearch-k8s-operator/issues/442
      s3.client.default.identity_token_file: /usr/share/opensearch/config/aws-iam-token/token
    resources:
      requests:
        memory: "2190Mi"
        cpu: "100m"
      limits:
        memory: "2190Mi"
    roles:
    - "ingest"
    diskSize: 10Gi
    topologySpreadConstraints:
    - maxSkew: 1
      topologyKey: kubernetes.io/hostname
      whenUnsatisfiable: DoNotSchedule
      labelSelector:
        matchLabels:
          opster.io/opensearch-cluster: opensearch-staging
          opster.io/opensearch-nodepool: ingest
    pdb:
      enable: true
      maxUnavailable: 1
    persistence:
      pvc:
        storageClass: data-hub-gp3
        accessModes:
          - ReadWriteOnce
