twitterAdsApi:
  # 18ce53up4ko - eLife Journal
  # 18ce543rvpg - eLife Community
  # 18ce555euao - Preprint Review
  # 18ce55b1rc9 - Sciety
  - dataPipelineId: twitter_ads_api_campaign_details
    source:
      accountIds: ['18ce53up4ko', '18ce543rvpg', '18ce555euao', '18ce55b1rc9']
      resource: '/11/accounts/{account_id}/campaigns'
      secrets:
        parametersFromFile:
          - parameterName: api_key
            filePathEnvName: TWITTER_API_KEY_FILE_PATH
          - parameterName: api_secret
            filePathEnvName: TWITTER_API_SECRET_FILE_PATH
          - parameterName: access_token
            filePathEnvName: TWITTER_ACCESS_TOKEN_FILE_PATH
          - parameterName: access_token_secret
            filePathEnvName: TWITTER_ACCESS_TOKEN_SECRET_FILE_PATH
    target:
      projectName: 'elife-data-pipeline'
      datasetName: '{ENV}'
      tableName: twitter_campaign_details

  - dataPipelineId: twitter_ads_api_campaign_audience_reach
    source:
      accountIds: ['18ce53up4ko', '18ce543rvpg', '18ce555euao', '18ce55b1rc9']
      resource: '/11/stats/accounts/{account_id}/reach/campaigns'
      secrets:
        parametersFromFile:
          - parameterName: api_key
            filePathEnvName: TWITTER_API_KEY_FILE_PATH
          - parameterName: api_secret
            filePathEnvName: TWITTER_API_SECRET_FILE_PATH
          - parameterName: access_token
            filePathEnvName: TWITTER_ACCESS_TOKEN_FILE_PATH
          - parameterName: access_token_secret
            filePathEnvName: TWITTER_ACCESS_TOKEN_SECRET_FILE_PATH
      apiQueryParameters:
        parameterValues:
          fromBigQuery:
            projectName: 'elife-data-pipeline'
            sqlQuery: |-
              SELECT 
                DISTINCT t_data.id AS entity_id,
                CAST(CAST(t_data.created_at AS DATE) AS STRING) AS start_date
              FROM `elife-data-pipeline.{ENV}.v_latest_twitter_campaign_details`
              JOIN UNNEST(data) AS t_data
              WHERE  -- the campaigns before '2015-01-02' has to be filtered because of api limits
              CAST(t_data.created_at AS DATE) > CAST('2015-01-02' AS DATE)
              AND DATE_ADD(CAST(t_data.created_at AS DATE), INTERVAL 600 DAY) > CURRENT_DATE()  --(maxPeriodInDays)
              AND request.params.account_id = '{account_id}'
          maxPeriodInDays: 600
        parameterNamesFor:
          entityId: campaign_ids
          startDate: start_time
          endDate: end_time
    target:
      projectName: 'elife-data-pipeline'
      datasetName: '{ENV}'
      tableName: twitter_campaign_audience_reach

  - dataPipelineId: twitter_ads_api_campaign_clicks_and_impressions
    source:
      accountIds: ['18ce53up4ko', '18ce543rvpg', '18ce555euao', '18ce55b1rc9']
      resource: '/11/stats/accounts/{account_id}?entity=CAMPAIGN&granularity=DAY&metric_groups=ENGAGEMENT'
      secrets:
        parametersFromFile:
          - parameterName: api_key
            filePathEnvName: TWITTER_API_KEY_FILE_PATH
          - parameterName: api_secret
            filePathEnvName: TWITTER_API_SECRET_FILE_PATH
          - parameterName: access_token
            filePathEnvName: TWITTER_ACCESS_TOKEN_FILE_PATH
          - parameterName: access_token_secret
            filePathEnvName: TWITTER_ACCESS_TOKEN_SECRET_FILE_PATH
      apiQueryParameters:
        parameterValues:
          fromBigQuery:
            projectName: 'elife-data-pipeline'
            sqlQuery: |-
              WITH t_all_campaigns AS(
                SELECT 
                  DISTINCT 
                  t_data.id AS entity_id,
                  CAST(t_data.created_at AS DATE) AS entity_creation_date
                FROM `elife-data-pipeline.{ENV}.v_latest_twitter_campaign_details`
                JOIN UNNEST(data) AS t_data
                WHERE  -- the campaigns before '2015-01-02' has to be filtered because of api limits
                CAST(t_data.created_at AS DATE) > CAST('2015-01-02' AS DATE)
                AND request.params.account_id = '{account_id}'
              ),
              t_max_start_and_end_time_by_campaign_and_placement AS (
                SELECT 
                  id AS entity_id,
                  request.params.placement,
                  MAX(request.params.start_time) OVER (PARTITION BY id, request.params.placement) AS max_start_time,
                  MAX(request.params.end_time) OVER (PARTITION BY id, request.params.placement) AS max_end_time
                FROM
                `elife-data-pipeline.{ENV}.v_latest_twitter_campaign_clicks_and_impressions`
              ),
              t_min_start_and_end_time_per_campaign AS (
                SELECT 
                  entity_id,
                  CAST(MIN(max_start_time) AS DATE) AS start_date,
                  CAST(MIN(max_end_time) AS DATE) AS end_date,
                FROM t_max_start_and_end_time_by_campaign_and_placement 
                GROUP BY entity_id
              ),
              t_campaign_and_dates AS (
                SELECT 
                  t_campaign.entity_id,
                  t_campaign.entity_creation_date,
                  COALESCE(
                    t_date.end_date,
                    t_date.start_date,
                    t_campaign.entity_creation_date
                  ) AS calculated_date,
                FROM t_all_campaigns AS t_campaign
                LEFT JOIN t_min_start_and_end_time_per_campaign AS t_date
                ON t_campaign.entity_id = t_date.entity_id
              )
              SELECT 
                entity_id, 
                CAST(entity_creation_date AS STRING) AS entity_creation_date,
                CAST(calculated_date AS STRING) AS start_date,
              FROM t_campaign_and_dates
              WHERE ABS(DATE_DIFF(entity_creation_date, calculated_date, DAY)) < 91 --(maxPeriodInDays-1)
          maxPeriodInDays: 92  # 7*13+1 (+1 is for getting out from periodBatchSizeInDays for final end_date because of using start_time )
          periodBatchSizeInDays: 7  # 7 days is the max batch size for this api endpoint
          placementValue: ['PUBLISHER_NETWORK','ALL_ON_TWITTER']
        parameterNamesFor:
          entityId: entity_ids
          startDate: start_time
          endDate: end_time
          placement: placement
    target:
      projectName: 'elife-data-pipeline'
      datasetName: '{ENV}'
      tableName: twitter_campaign_clicks_and_impressions
    batchSize: 250  # because the API ratelimit is 250 requests per 15 min

  - dataPipelineId: twitter_ads_api_campaign_costs
    source:
      accountIds: ['18ce53up4ko', '18ce543rvpg', '18ce555euao', '18ce55b1rc9']
      resource: '/11/stats/accounts/{account_id}?entity=CAMPAIGN&granularity=DAY&metric_groups=BILLING'
      secrets:
        parametersFromFile:
          - parameterName: api_key
            filePathEnvName: TWITTER_API_KEY_FILE_PATH
          - parameterName: api_secret
            filePathEnvName: TWITTER_API_SECRET_FILE_PATH
          - parameterName: access_token
            filePathEnvName: TWITTER_ACCESS_TOKEN_FILE_PATH
          - parameterName: access_token_secret
            filePathEnvName: TWITTER_ACCESS_TOKEN_SECRET_FILE_PATH
      apiQueryParameters:
        parameterValues:
          fromBigQuery:
            projectName: 'elife-data-pipeline'
            sqlQuery: |-
              WITH t_all_campaigns AS(
                SELECT 
                  DISTINCT 
                  t_data.id AS entity_id,
                  CAST(t_data.created_at AS DATE) AS entity_creation_date
                FROM `elife-data-pipeline.{ENV}.v_latest_twitter_campaign_details`
                JOIN UNNEST(data) AS t_data
                WHERE  -- the campaigns before '2015-01-02' has to be filtered because of api limits
                CAST(t_data.created_at AS DATE) > CAST('2015-01-02' AS DATE)
                AND request.params.account_id = '{account_id}'
              ),
              t_max_start_and_end_time_by_campaign_and_placement AS (
                SELECT 
                  id AS entity_id,
                  request.params.placement,
                  MAX(request.params.start_time) OVER (PARTITION BY id, request.params.placement) AS max_start_time,
                  MAX(request.params.end_time) OVER (PARTITION BY id, request.params.placement) AS max_end_time
                FROM
                `elife-data-pipeline.{ENV}.v_latest_twitter_campaign_costs`
              ),
              t_min_start_and_end_time_per_campaign AS (
                SELECT 
                  entity_id,
                  CAST(MIN(max_start_time) AS DATE) AS start_date,
                  CAST(MIN(max_end_time) AS DATE) AS end_date,
                FROM t_max_start_and_end_time_by_campaign_and_placement 
                GROUP BY entity_id
              ),
              t_campaign_and_dates AS (
                SELECT 
                  t_campaign.entity_id,
                  t_campaign.entity_creation_date,
                  COALESCE(
                    t_date.end_date,
                    t_date.start_date,
                    t_campaign.entity_creation_date
                  ) AS calculated_date,
                FROM t_all_campaigns AS t_campaign
                LEFT JOIN t_min_start_and_end_time_per_campaign AS t_date
                ON t_campaign.entity_id = t_date.entity_id
              )
              SELECT 
                entity_id, 
                CAST(entity_creation_date AS STRING) AS entity_creation_date,
                -- We fetch previous 7 days even we already have the data, because Twitter might adjust cost retrospectively
                -- 8=7+1 (for yesterday)
                CAST(LEAST(calculated_date, DATE_SUB(CURRENT_DATE(), INTERVAL 8 DAY)) AS STRING) AS start_date,
              FROM t_campaign_and_dates
              WHERE ABS(DATE_DIFF(entity_creation_date, calculated_date, DAY)) < 91 --(maxPeriodInDays-1)
          maxPeriodInDays: 92 # 7*13+1 (+1 is for getting out from periodBatchSizeInDays for final end_date because of using start_time )
          periodBatchSizeInDays: 7  # 7 days is the max batch size for this api endpoint
          placementValue: ['PUBLISHER_NETWORK','ALL_ON_TWITTER']
        parameterNamesFor:
          entityId: entity_ids
          startDate: start_time
          endDate: end_time
          placement: placement
    target:
      projectName: 'elife-data-pipeline'
      datasetName: '{ENV}'
      tableName: twitter_campaign_costs
    batchSize: 250  # because the API ratelimit is 250 requests per 15 min
