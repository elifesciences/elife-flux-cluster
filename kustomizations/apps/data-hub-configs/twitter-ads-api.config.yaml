twitterAdsApi:
  - dataPipelineId: twitter_ads_api_campaign_details_elife_journal
    source:
      resource: '/11/accounts/18ce53up4ko/campaigns'
      secrets:
        parametersFromFile:
          - parameterName: api_key
            filePathEnvName: TWITTER_API_KEY_FILE_PATH
          - parameterName: api_secret
            filePathEnvName: TWITTER_API_SECRET_FILE_PATH
          - parameterName: access_token
            filePathEnvName: TWITTER_ACCESS_TOKEN_FILE_PATH
          - parameterName: access_token_secret
            filePathEnvName: TWITTER_ACCESS_TOKEN_SECRET_FILE_PATH
    target:
      projectName: 'elife-data-pipeline'
      datasetName: '{ENV}'
      tableName: twitter_campaign_details_elife_journal

  - dataPipelineId: twitter_ads_api_campaign_reach_elife_journal
    source:
      resource: '/11/stats/accounts/18ce53up4ko/reach/campaigns'
      secrets:
        parametersFromFile:
          - parameterName: api_key
            filePathEnvName: TWITTER_API_KEY_FILE_PATH
          - parameterName: api_secret
            filePathEnvName: TWITTER_API_SECRET_FILE_PATH
          - parameterName: access_token
            filePathEnvName: TWITTER_ACCESS_TOKEN_FILE_PATH
          - parameterName: access_token_secret
            filePathEnvName: TWITTER_ACCESS_TOKEN_SECRET_FILE_PATH
      apiQueryParameters:
        parameterValues:
          fromBigQuery:
            projectName: 'elife-data-pipeline'
            sqlQuery: |-
              SELECT 
                DISTINCT t_data.id AS entity_id,
                CAST(CAST(t_data.created_at AS DATE) AS STRING) AS start_date
              FROM `elife-data-pipeline.{ENV}.v_latest_twitter_campaign_details_elife_journal`
              JOIN UNNEST(data) AS t_data
              WHERE  -- the campaigns before '2015-01-02' has to be filtered because of api limits
              CAST(t_data.created_at AS DATE) > CAST('2015-01-02' AS DATE)
              AND DATE_ADD(CAST(t_data.created_at AS DATE), INTERVAL 600 DAY) > CURRENT_DATE()  --(maxPeriodInDays)
          maxPeriodInDays: 600
        parameterNamesFor:
          entityId: campaign_ids
          startDate: start_time
          endDate: end_time
    target:
      projectName: 'elife-data-pipeline'
      datasetName: '{ENV}'
      tableName: twitter_campaign_reach_elife_journal

  - dataPipelineId: twitter_ads_api_campaign_clicks_and_impressions_elife_journal
    source:
      resource: '/11/stats/accounts/18ce53up4ko?entity=CAMPAIGN&granularity=DAY&metric_groups=ENGAGEMENT'
      secrets:
        parametersFromFile:
          - parameterName: api_key
            filePathEnvName: TWITTER_API_KEY_FILE_PATH
          - parameterName: api_secret
            filePathEnvName: TWITTER_API_SECRET_FILE_PATH
          - parameterName: access_token
            filePathEnvName: TWITTER_ACCESS_TOKEN_FILE_PATH
          - parameterName: access_token_secret
            filePathEnvName: TWITTER_ACCESS_TOKEN_SECRET_FILE_PATH
      apiQueryParameters:
        parameterValues:
          fromBigQuery:
            projectName: 'elife-data-pipeline'
            sqlQuery: |-
              WITH t_all_campaigns AS(
                SELECT 
                  DISTINCT 
                  t_data.id AS entity_id,
                  CAST(t_data.created_at AS DATE) AS entity_creation_date
                FROM `elife-data-pipeline.{ENV}.v_latest_twitter_campaign_details_elife_journal`
                JOIN UNNEST(data) AS t_data
                WHERE  -- the campaigns before '2015-01-02' has to be filtered because of api limits
                CAST(t_data.created_at AS DATE) > CAST('2015-01-02' AS DATE)
              ),
              t_max_start_time_by_campaign_and_placement AS (
                SELECT 
                  t_data.id AS entity_id,
                  request.params.placement,
                  MAX(request.params.start_time) OVER (PARTITION BY t_data.id, request.params.placement) AS max_start_time,
                  MAX(request.params.end_time) OVER (PARTITION BY t_data.id, request.params.placement) AS max_end_time
                FROM
                `elife-data-pipeline.{ENV}.v_latest_twitter_campaign_clicks_and_impressions_elife_journal`
                JOIN UNNEST(data) AS t_data
              ),
              t_min_start_time_per_campaign AS (
                SELECT 
                  entity_id,
                  CAST(MIN(max_start_time) AS DATE) AS start_date,
                  CAST(MIN(max_end_time) AS DATE) AS end_date,
                FROM t_max_start_time_by_campaign_and_placement 
                GROUP BY entity_id
              ),
              t_campaign_and_dates AS (
                SELECT 
                  t_campaign.entity_id,
                  t_campaign.entity_creation_date,
                  IFNULL(t_calculated_date.start_date, t_campaign.entity_creation_date) AS start_date,
                  IFNULL(
                    t_calculated_date.end_date,
                    DATE_ADD(CAST(t_campaign.entity_creation_date AS DATE), INTERVAL 92 DAY) --(maxPeriodInDays)
                  ) AS end_date,
                FROM t_all_campaigns AS t_campaign
                LEFT JOIN t_min_start_time_per_campaign AS t_calculated_date
                ON t_campaign.entity_id = t_calculated_date.entity_id
              )
              SELECT 
                entity_id, 
                CAST(entity_creation_date AS STRING) AS entity_creation_date,
                CAST(start_date AS STRING) AS start_date
              FROM t_campaign_and_dates
              WHERE ABS(DATE_DIFF(entity_creation_date, end_date, DAY)) < 91 --(maxPeriodInDays-1)
          maxPeriodInDays: 92 # 7*13+1 (+1 is for getting out from periodBatchSizeInDays for final end_date because of usin start_time )
          periodBatchSizeInDays: 7  # 7 days is the max batch size for this api endpoint
          placementValue: ['PUBLISHER_NETWORK','ALL_ON_TWITTER']
        parameterNamesFor:
          entityId: entity_ids
          startDate: start_time
          endDate: end_time
          placement: placement
    target:
      projectName: 'elife-data-pipeline'
      datasetName: '{ENV}'
      tableName: twitter_campaign_clicks_and_impressions_elife_journal
    batchSize: 250  # because the API ratelimit is 250 requests per 15 min
